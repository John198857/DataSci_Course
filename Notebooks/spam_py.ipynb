{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The spam filter\n",
    "\n",
    "### Introduction\n",
    "\n",
    "In this example, I develop a **spam filter**, that is, an algorithm that classifies e-mail messages as either spam or non-spam, based on a collection of attributes such as the frequency of certain words or characters. The algorithm is based on a **decision tree** obtained with the Python package **scikit-learn**. I use data collected at Hewlett-Packard by merging: (a) a collection of spam e-mail from the company postmaster and the individuals who had filed spam, and (b) a collection of non-spam e-mail, extracted from filed work and personal e-mail. \n",
    "\n",
    "In this example, I have to take into account that the false positive rate, that is, of non-spam messages wrongly classified as spam, is expected to be very low in a acceptable spam filter. The data set contains data on 4,601 e-mail messages. Among these messages, 1,813 have been classified as spam. The variables are:\n",
    "\n",
    "* A dummy for the e-mail being considered spam (`spam`).\n",
    "\n",
    "* 48 numeric variables whose names start with 'word_', followed by a word. They indicate the **frequency**, in percentage scale, with which that word appears in the message. Example: `word_make=0.21`, for a particular message, means that 0.21% of the words in the message match the word 'make'.\n",
    "\n",
    "* 3 numeric variables indicating, respectively, the **average length** of uninterrupted sequences of capital letters, the length of the longest uninterrupted sequence of capital letters and the total number of capital letters in the message.\n",
    "\n",
    "### Importing the data\n",
    "\n",
    "I import the data with the `pandas` function `read_csv`. The data set has 4,601 rows and 52 columns, all numeric. I print the structure of the data set only for the first and the last five variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "spam = pd.read_csv('https://raw.githubusercontent.com/iese-bad/' +\n",
    "    'DataSci/master/Data/spam.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 5 columns):\n",
      "word_make       4601 non-null float64\n",
      "word_address    4601 non-null float64\n",
      "word_all        4601 non-null float64\n",
      "word_3d         4601 non-null float64\n",
      "word_our        4601 non-null float64\n",
      "dtypes: float64(5)\n",
      "memory usage: 179.8 KB\n"
     ]
    }
   ],
   "source": [
    "spam.iloc[:, 0:5].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4601 entries, 0 to 4600\n",
      "Data columns (total 5 columns):\n",
      "word_conference    4601 non-null float64\n",
      "cap_ave            4601 non-null float64\n",
      "cap_long           4601 non-null int64\n",
      "cap_total          4601 non-null int64\n",
      "spam               4601 non-null int64\n",
      "dtypes: float64(2), int64(3)\n",
      "memory usage: 179.8 KB\n"
     ]
    }
   ],
   "source": [
    "spam.iloc[:, 47:52].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a decision tree\n",
    "\n",
    "I specify the `y` and `X` components of the equation as usual in scikit-learn unsupervised methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = spam.iloc[:, 51]\n",
    "X = spam.iloc[:, 0:51]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn has a module called `tree`, with various decision tree methods. I use the method `DecisionTreeRegressor` for consistency with the R notebook of the same example and the method `export_graphviz` for plotting trees. Note that, for using this last method, you need to have **Graphviz** (which is an open source, independent app) installed in your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fitting a decision tree is the same as fitting any other supervised learning model in `scikit-learn`. The argument `min_impurity_decrease=0.01` will be justified below. Warning: this parameter was introduced in version 0.19 of scikit-learn, so you have to update it if your version is older."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.01,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TREE1 = DecisionTreeRegressor(min_impurity_decrease=0.01)\n",
    "TREE1.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before evaluting this model, we plot the tree, for a better understanding of how it works. `export_graphviz` exports the tree to a format (`dot`) which can be managed by **Graphviz**. Graphviz is an open source app, not part of Python, which you need to have installed in your computer. The three last lines of the following code chunk are used for generating a PDF version of the DOT representation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dot_data = export_graphviz(TREE1, out_file=None,\n",
    "  feature_names=spam.columns[0:51])\n",
    "# import pydotplus\n",
    "# graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "# graph.write_pdf('tree.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assuming that Graphviz is installed, I load the package `graphviz` and ask for the plot. Note: the first two lines are needed in Windows for Python to find the Graphviz executable. Installing Graphviz with Homebrew in macintosh fixes this type of problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.38.0 (20140413.2041)\n",
       " -->\n",
       "<!-- Title: Tree Pages: 1 -->\n",
       "<svg width=\"364pt\" height=\"358pt\"\n",
       " viewBox=\"0.00 0.00 364.50 358.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 354)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" stroke=\"none\" points=\"-4,4 -4,-354 360.499,-354 360.499,4 -4,4\"/>\n",
       "<!-- 0 -->\n",
       "<g id=\"node1\" class=\"node\"><title>0</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"313.542,-350 172.457,-350 172.457,-286 313.542,-286 313.542,-350\"/>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-334.8\" font-family=\"Times,serif\" font-size=\"14.00\">word_remove &lt;= 0.01</text>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-320.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 0.239</text>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-306.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 4601</text>\n",
       "<text text-anchor=\"middle\" x=\"243\" y=\"-292.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 0.394</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g id=\"node2\" class=\"node\"><title>1</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"241.815,-250 114.184,-250 114.184,-186 241.815,-186 241.815,-250\"/>\n",
       "<text text-anchor=\"middle\" x=\"178\" y=\"-234.8\" font-family=\"Times,serif\" font-size=\"14.00\">word_free &lt;= 0.135</text>\n",
       "<text text-anchor=\"middle\" x=\"178\" y=\"-220.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 0.2</text>\n",
       "<text text-anchor=\"middle\" x=\"178\" y=\"-206.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 3794</text>\n",
       "<text text-anchor=\"middle\" x=\"178\" y=\"-192.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 0.276</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g id=\"edge1\" class=\"edge\"><title>0&#45;&gt;1</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M222.433,-285.992C216.683,-277.323 210.355,-267.782 204.321,-258.685\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"207.099,-256.541 198.655,-250.142 201.266,-260.411 207.099,-256.541\"/>\n",
       "<text text-anchor=\"middle\" x=\"193.695\" y=\"-270.445\" font-family=\"Times,serif\" font-size=\"14.00\">True</text>\n",
       "</g>\n",
       "<!-- 6 -->\n",
       "<g id=\"node7\" class=\"node\"><title>6</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"356.499,-243 259.5,-243 259.5,-193 356.499,-193 356.499,-243\"/>\n",
       "<text text-anchor=\"middle\" x=\"308\" y=\"-227.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 0.05</text>\n",
       "<text text-anchor=\"middle\" x=\"308\" y=\"-213.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 807</text>\n",
       "<text text-anchor=\"middle\" x=\"308\" y=\"-199.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 0.947</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;6 -->\n",
       "<g id=\"edge6\" class=\"edge\"><title>0&#45;&gt;6</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M263.566,-285.992C270.785,-275.107 278.917,-262.847 286.232,-251.818\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"289.28,-253.556 291.89,-243.288 283.446,-249.687 289.28,-253.556\"/>\n",
       "<text text-anchor=\"middle\" x=\"296.851\" y=\"-263.591\" font-family=\"Times,serif\" font-size=\"14.00\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g id=\"node3\" class=\"node\"><title>2</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"179.667,-150 42.3324,-150 42.3324,-86 179.667,-86 179.667,-150\"/>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-134.8\" font-family=\"Times,serif\" font-size=\"14.00\">word_money &lt;= 0.01</text>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-120.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 0.145</text>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-106.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 3108</text>\n",
       "<text text-anchor=\"middle\" x=\"111\" y=\"-92.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 0.177</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g id=\"edge2\" class=\"edge\"><title>1&#45;&gt;2</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M156.8,-185.992C150.812,-177.234 144.216,-167.585 137.939,-158.404\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"140.824,-156.422 132.291,-150.142 135.045,-160.373 140.824,-156.422\"/>\n",
       "</g>\n",
       "<!-- 5 -->\n",
       "<g id=\"node6\" class=\"node\"><title>5</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"294.499,-143 197.5,-143 197.5,-93 294.499,-93 294.499,-143\"/>\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-127.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 0.198</text>\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-113.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 686</text>\n",
       "<text text-anchor=\"middle\" x=\"246\" y=\"-99.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 0.729</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;5 -->\n",
       "<g id=\"edge5\" class=\"edge\"><title>1&#45;&gt;5</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M199.515,-185.992C207.068,-175.107 215.575,-162.847 223.228,-151.818\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.322,-153.499 229.147,-143.288 220.57,-149.508 226.322,-153.499\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g id=\"node4\" class=\"node\"><title>3</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"103.999,-50 0.000488277,-50 0.000488277,-0 103.999,-0 103.999,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"51.9995\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 0.117</text>\n",
       "<text text-anchor=\"middle\" x=\"51.9995\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 2915</text>\n",
       "<text text-anchor=\"middle\" x=\"51.9995\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 0.136</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g id=\"edge3\" class=\"edge\"><title>2&#45;&gt;3</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M90.8601,-85.9375C85.1517,-77.133 78.9216,-67.5239 73.155,-58.6297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"75.9564,-56.5168 67.5794,-50.0301 70.0829,-60.3249 75.9564,-56.5168\"/>\n",
       "</g>\n",
       "<!-- 4 -->\n",
       "<g id=\"node5\" class=\"node\"><title>4</title>\n",
       "<polygon fill=\"none\" stroke=\"black\" points=\"218.499,-50 121.5,-50 121.5,-0 218.499,-0 218.499,-50\"/>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-34.8\" font-family=\"Times,serif\" font-size=\"14.00\">mse = 0.161</text>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-20.8\" font-family=\"Times,serif\" font-size=\"14.00\">samples = 193</text>\n",
       "<text text-anchor=\"middle\" x=\"170\" y=\"-6.8\" font-family=\"Times,serif\" font-size=\"14.00\">value = 0.798</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;4 -->\n",
       "<g id=\"edge4\" class=\"edge\"><title>2&#45;&gt;4</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M131.139,-85.9375C136.847,-77.133 143.077,-67.5239 148.844,-58.6297\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"151.916,-60.3249 154.42,-50.0301 146.043,-56.5168 151.916,-60.3249\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.files.Source at 0x1a17616da0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import os\n",
    "# os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "import graphviz\n",
    "graphviz.Source(dot_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph is easy to interpret. The box on top is the root node, with 4,601 instances. The average of the predicted variable (`spam`), that is, the spam rate, is 39.4%, and that the mean sum of squared residuals (actual value minus mean) is 0.239. The optimal split, based on `word_remove`, is the one that yields the maximum reduction of the sum of squared residuals or, equivalently, of the weighted average of the MSE values of the branches.\n",
    "\n",
    "In the left branch (instances satisfying `word_remove<=0.01`), we get 3,749 instances, with 27.6% spam rate, and, in the right branch, 807 instances, with spam rate 94.7%. This last brach is not further split, because the potential splits would not improve the mse enough, given the `min_impurity_decrease=0.01` specification. On the left branch we see two more splits.\n",
    "\n",
    "In the end, this tree partitionates the sample in four groups, corresponding to the four leaves. The spam rate in any of these leaves is taken as the score for all the instances in that leaf. So, we have four different scores: 0.947, 0.729, 0.136 and 0.798. We see below how to get this scores without plotting, which is not feasible for bigger trees.\n",
    "\n",
    "### Predictive scores and confusion matrix\n",
    "\n",
    "Since we are using `DecisionTreeRegressor` (with `DecisionTreeClassifier` is a bit more complicated), obtaining the scores is as easy as in a linear regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam   False  True \n",
      "row_0              \n",
      "False   2520    395\n",
      "True     268   1418\n"
     ]
    }
   ],
   "source": [
    "score1 = TREE1.predict(X)\n",
    "conf1 = pd.crosstab(score1 > 0.5, spam['spam']==1)\n",
    "print(conf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.782"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp1 = conf1.iloc[1, 1]/(conf1.iloc[0, 1] + conf1.iloc[1, 1])\n",
    "tp1.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.096"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp1 = conf1.iloc[1, 0]/(conf1.iloc[0, 0] + conf1.iloc[1, 0])\n",
    "fp1.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, in this case, the data set has been artificially created, by joining two collections which come from different sources. So, the proportion of spam in data is not the real one. This means that a statistic like the accuracy does not make sense. Nevertheless, we can evaluate the classifier examining the two columns of the confusion matrix separately, as we do when we look at the TP and FP rates. \n",
    "\n",
    "The TP rate is excellent, but the FP rate is a bit high for a spam filter. Can we improve these results with a better cutoff? Instead of exploring this with histograms, it is better to use crosstabulation here, since there are only 4 different scores, one for each leaf of the tree. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam         0    1\n",
      "row_0              \n",
      "0.135506  2520  395\n",
      "0.728863   186  500\n",
      "0.797927    39  154\n",
      "0.946716    43  764\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(score1, spam['spam']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see in the table a wide gap between 0.136 and 0.729. This is a by-product of the tree algorithm, which selects the splits so that they produce extreme scores. Here, lowering the cutoff would increase the proportion of positives and, in particular, the FP rate would increase, an undesired effect. Raising the cutoff, the FP rate would decrease, which could be interesting, but we would stop filtering 500 spam messages, which would leave us with a very poor filter.\n",
    "\n",
    "### Controlling pruning\n",
    "\n",
    "In `DecisionTreeRegressor`, pruning is controlled by the complexity parameter `min_impurity_decrease`. Any split that does not decrease the overall lack of fit by a factor equal to the specified value is not attempted. The main role of this parameter is to save computing time by pruning off splits that are obviously not worthwhile.\n",
    "\n",
    "To show you how this works, I change the specification to `cmin_impurity_decrease=0.001`, getting a tree with 21 leaves, involving 14 variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TREE2 = DecisionTreeRegressor(min_impurity_decrease=0.001)\n",
    "TREE2.fit(X, y)\n",
    "score2 = TREE2.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam   False  True \n",
      "row_0              \n",
      "False   2575    119\n",
      "True     213   1694\n"
     ]
    }
   ],
   "source": [
    "conf2 = pd.crosstab(score2 > 0.5, spam['spam']==1)\n",
    "print(conf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.934"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp2 = conf2.iloc[1, 1]/(conf2.iloc[0, 1] + conf2.iloc[1, 1])\n",
    "tp2.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.076"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp2 = conf2.iloc[1, 0]/(conf2.iloc[0, 0] + conf2.iloc[1, 0])\n",
    "fp2.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The confusion matrix looks a bit better, but we should check that this does not come at the price of overfitting. I leave that for the homework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
